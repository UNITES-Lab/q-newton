name: mistral-tiny-scaling
project: qnewton
command:
  - ${interpreter}
  - ${program}
  - ${args}
  - "--pretrained_model_name='mistralai/Mistral-7B-v0.1'"
  - "--enable_newton=True"
  - "--batch_size=128"
  - "--learning_rate=1e-1"
  - "--warmup_steps=1000"
  - "--evaluation_steps=500"
  - "--num_epochs=3"
  - "--num_hidden_layers=3"
  - "--hidden_size=64"
  - "--intermediate_size=256"
  - "--max_position_embeddings=512"
  - "--profile_hessian_per_steps=50"
  - "--quantum_sparsity_ratio=1.0"
method: grid
metric:
  goal: minimize
  name: best_eval_loss
parameters:
  normalization_epsilon:
    values:
      - 1e-3
      - 5e-3
      - 1e-2
      - 5e-2
      - 1e-1
      - 5e-1
      - 1
      - 5
      - 1e1
      - 5e1
      - 1e2
      - 5e2
      - 1e3
      - 5e3
      - 1e4
      - 5e4

program: qnewton/train-mistral-tiny.py